[2018-05-09 15:08:11,302] INFO: tpe_transform took 0.008796 seconds
[2018-05-09 15:08:11,302] INFO: TPE using 0 trials
[2018-05-09 15:08:13,343] INFO: ==================================================
[2018-05-09 15:08:13,343] INFO: Task
[2018-05-09 15:08:13,343] INFO:      stacking_Learner@EnsembleLearner_Id@1
[2018-05-09 15:08:13,344] INFO: Param
[2018-05-09 15:08:13,344] INFO:      clf_skl_lr:
[2018-05-09 15:08:13,344] INFO:          learner: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
[2018-05-09 15:08:13,344] INFO:          param:
[2018-05-09 15:08:13,345] INFO:              C: 0.07671618346798499
[2018-05-09 15:08:13,345] INFO:              penalty: l1
[2018-05-09 15:08:13,345] INFO:              random_state: 42
[2018-05-09 15:08:13,345] INFO:          weight: 1.0
[2018-05-09 15:08:13,345] INFO:      clf_skl_rf:
[2018-05-09 15:08:13,345] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
[2018-05-09 15:08:13,345] INFO:          param:
[2018-05-09 15:08:13,345] INFO:              max_depth: 5
[2018-05-09 15:08:13,345] INFO:              max_features: 1.0
[2018-05-09 15:08:13,345] INFO:              min_samples_leaf: 8
[2018-05-09 15:08:13,346] INFO:              min_samples_split: 13
[2018-05-09 15:08:13,346] INFO:              n_estimators: 100
[2018-05-09 15:08:13,346] INFO:              n_jobs: 8
[2018-05-09 15:08:13,346] INFO:              random_state: 42
[2018-05-09 15:08:13,346] INFO:              verbose: 0
[2018-05-09 15:08:13,346] INFO:          weight: 0.2
[2018-05-09 15:08:13,346] INFO:      clf_xgb_tree:
[2018-05-09 15:08:13,346] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,
       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,
       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,
       objective='binary:logistic', reg_alpha=0, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=1)
[2018-05-09 15:08:13,346] INFO:          param:
[2018-05-09 15:08:13,347] INFO:              colsample_bylevel: 0.7062098719559918
[2018-05-09 15:08:13,347] INFO:              colsample_bytree: 0.9196220190766895
[2018-05-09 15:08:13,347] INFO:              gamma: 0.017077277166136128
[2018-05-09 15:08:13,347] INFO:              learning_rate: 0.018000000000000002
[2018-05-09 15:08:13,347] INFO:              max_depth: 8
[2018-05-09 15:08:13,347] INFO:              min_child_weight: 3.021380787506065e-07
[2018-05-09 15:08:13,347] INFO:              n_estimators: 450
[2018-05-09 15:08:13,347] INFO:              nthread: 8
[2018-05-09 15:08:13,347] INFO:              reg_alpha: 6.858955317701945
[2018-05-09 15:08:13,347] INFO:              reg_lambda: 3.6935926459831268
[2018-05-09 15:08:13,347] INFO:              seed: 42
[2018-05-09 15:08:13,348] INFO:              subsample: 0.9614815948278399
[2018-05-09 15:08:13,348] INFO:          weight: 0.2
[2018-05-09 15:08:13,348] INFO: Result
[2018-05-09 15:08:13,348] INFO:      Run     AUC     Shape
[2018-05-09 15:10:56,653] INFO:        1     0.785635     44601 x 54
[2018-05-09 15:13:43,946] INFO:        2     0.803935     44601 x 54
[2018-05-09 15:16:30,704] INFO:        3     0.794472     44602 x 54
[2018-05-09 15:16:30,911] INFO: AUC
[2018-05-09 15:16:30,912] INFO:      cv_mean: 0.794681
[2018-05-09 15:16:30,912] INFO:      cv_test: 0.800183
[2018-05-09 15:16:30,912] INFO: Time
[2018-05-09 15:16:30,912] INFO:      8 mins
[2018-05-09 15:16:30,912] INFO: --------------------------------------------------
[2018-05-09 15:20:51,422] INFO: tpe_transform took 0.008323 seconds
[2018-05-09 15:20:51,422] INFO: TPE using 1/1 trials with best loss -0.799493
[2018-05-09 15:20:53,356] INFO: ==================================================
[2018-05-09 15:20:53,356] INFO: Task
[2018-05-09 15:20:53,356] INFO:      stacking_Learner@EnsembleLearner_Id@2
[2018-05-09 15:20:53,357] INFO: Param
[2018-05-09 15:20:53,357] INFO:      clf_skl_lr:
[2018-05-09 15:20:53,357] INFO:          learner: LogisticRegression(C=0.07671618346798499, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 15:20:53,357] INFO:          param:
[2018-05-09 15:20:53,357] INFO:              C: 5.420647371243757e-07
[2018-05-09 15:20:53,357] INFO:              penalty: l2
[2018-05-09 15:20:53,357] INFO:              random_state: 42
[2018-05-09 15:20:53,357] INFO:          weight: 1.0
[2018-05-09 15:20:53,357] INFO:      clf_skl_rf:
[2018-05-09 15:20:53,358] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features=1.0, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=8, min_samples_split=13,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 15:20:53,358] INFO:          param:
[2018-05-09 15:20:53,358] INFO:              max_depth: 6
[2018-05-09 15:20:53,358] INFO:              max_features: 0.6000000000000001
[2018-05-09 15:20:53,358] INFO:              min_samples_leaf: 9
[2018-05-09 15:20:53,358] INFO:              min_samples_split: 8
[2018-05-09 15:20:53,358] INFO:              n_estimators: 760
[2018-05-09 15:20:53,358] INFO:              n_jobs: 8
[2018-05-09 15:20:53,358] INFO:              random_state: 42
[2018-05-09 15:20:53,358] INFO:              verbose: 0
[2018-05-09 15:20:53,358] INFO:          weight: 0.4
[2018-05-09 15:20:53,359] INFO:      clf_xgb_tree:
[2018-05-09 15:20:53,359] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.7062098719559918,
       colsample_bytree=0.9196220190766895, gamma=0.017077277166136128,
       learning_rate=0.018000000000000002, max_delta_step=0, max_depth=8,
       min_child_weight=3.021380787506065e-07, missing=None,
       n_estimators=450, nthread=8, objective='binary:logistic',
       reg_alpha=6.858955317701945, reg_lambda=3.6935926459831268,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.9614815948278399)
[2018-05-09 15:20:53,359] INFO:          param:
[2018-05-09 15:20:53,359] INFO:              colsample_bylevel: 0.9867883156710024
[2018-05-09 15:20:53,359] INFO:              colsample_bytree: 0.6238327062557556
[2018-05-09 15:20:53,359] INFO:              gamma: 4.719154428058338e-07
[2018-05-09 15:20:53,359] INFO:              learning_rate: 0.028
[2018-05-09 15:20:53,359] INFO:              max_depth: 3
[2018-05-09 15:20:53,359] INFO:              min_child_weight: 6.531538535946589e-07
[2018-05-09 15:20:53,359] INFO:              n_estimators: 780
[2018-05-09 15:20:53,359] INFO:              nthread: 8
[2018-05-09 15:20:53,360] INFO:              reg_alpha: 5.841267062464207e-09
[2018-05-09 15:20:53,360] INFO:              reg_lambda: 7.333803522626126e-05
[2018-05-09 15:20:53,360] INFO:              seed: 42
[2018-05-09 15:20:53,360] INFO:              subsample: 0.8271715847071177
[2018-05-09 15:20:53,360] INFO:          weight: 0.0
[2018-05-09 15:20:53,360] INFO: Result
[2018-05-09 15:20:53,360] INFO:      Run     AUC     Shape
[2018-05-09 15:23:53,127] INFO:        1     0.785545     44601 x 54
[2018-05-09 15:26:42,788] INFO:        2      0.80317     44601 x 54
[2018-05-09 15:29:34,177] INFO:        3     0.794864     44602 x 54
[2018-05-09 15:29:34,374] INFO: AUC
[2018-05-09 15:29:34,374] INFO:      cv_mean: 0.794526
[2018-05-09 15:29:34,375] INFO:      cv_test: 0.800768
[2018-05-09 15:29:34,375] INFO: Time
[2018-05-09 15:29:34,375] INFO:      8 mins
[2018-05-09 15:29:34,375] INFO: --------------------------------------------------
[2018-05-09 15:34:21,547] INFO: tpe_transform took 0.008354 seconds
[2018-05-09 15:34:21,547] INFO: TPE using 2/2 trials with best loss -0.800525
[2018-05-09 15:34:23,493] INFO: ==================================================
[2018-05-09 15:34:23,493] INFO: Task
[2018-05-09 15:34:23,493] INFO:      stacking_Learner@EnsembleLearner_Id@3
[2018-05-09 15:34:23,493] INFO: Param
[2018-05-09 15:34:23,493] INFO:      clf_skl_lr:
[2018-05-09 15:34:23,493] INFO:          learner: LogisticRegression(C=5.420647371243757e-07, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 15:34:23,493] INFO:          param:
[2018-05-09 15:34:23,493] INFO:              C: 33.513553677322896
[2018-05-09 15:34:23,494] INFO:              penalty: l2
[2018-05-09 15:34:23,494] INFO:              random_state: 42
[2018-05-09 15:34:23,494] INFO:          weight: 1.0
[2018-05-09 15:34:23,494] INFO:      clf_skl_rf:
[2018-05-09 15:34:23,494] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=6, max_features=0.6000000000000001,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=9,
            min_samples_split=8, min_weight_fraction_leaf=0.0,
            n_estimators=760, n_jobs=8, oob_score=False, random_state=42,
            verbose=0, warm_start=False)
[2018-05-09 15:34:23,494] INFO:          param:
[2018-05-09 15:34:23,494] INFO:              max_depth: 7
[2018-05-09 15:34:23,494] INFO:              max_features: 0.45
[2018-05-09 15:34:23,494] INFO:              min_samples_leaf: 13
[2018-05-09 15:34:23,494] INFO:              min_samples_split: 10
[2018-05-09 15:34:23,495] INFO:              n_estimators: 150
[2018-05-09 15:34:23,495] INFO:              n_jobs: 8
[2018-05-09 15:34:23,495] INFO:              random_state: 42
[2018-05-09 15:34:23,495] INFO:              verbose: 0
[2018-05-09 15:34:23,495] INFO:          weight: 0.8
[2018-05-09 15:34:23,495] INFO:      clf_xgb_tree:
[2018-05-09 15:34:23,495] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.9867883156710024,
       colsample_bytree=0.6238327062557556, gamma=4.719154428058338e-07,
       learning_rate=0.028, max_delta_step=0, max_depth=3,
       min_child_weight=6.531538535946589e-07, missing=None,
       n_estimators=780, nthread=8, objective='binary:logistic',
       reg_alpha=5.841267062464207e-09, reg_lambda=7.333803522626126e-05,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.8271715847071177)
[2018-05-09 15:34:23,495] INFO:          param:
[2018-05-09 15:34:23,495] INFO:              colsample_bylevel: 0.7696145472542932
[2018-05-09 15:34:23,495] INFO:              colsample_bytree: 0.7838021821310273
[2018-05-09 15:34:23,496] INFO:              gamma: 0.00016706319761478086
[2018-05-09 15:34:23,496] INFO:              learning_rate: 0.006
[2018-05-09 15:34:23,496] INFO:              max_depth: 5
[2018-05-09 15:34:23,496] INFO:              min_child_weight: 7.645991430490395
[2018-05-09 15:34:23,496] INFO:              n_estimators: 610
[2018-05-09 15:34:23,496] INFO:              nthread: 8
[2018-05-09 15:34:23,496] INFO:              reg_alpha: 6.366961566352447e-08
[2018-05-09 15:34:23,496] INFO:              reg_lambda: 3.1290232860923855e-05
[2018-05-09 15:34:23,496] INFO:              seed: 42
[2018-05-09 15:34:23,496] INFO:              subsample: 0.8616594078010396
[2018-05-09 15:34:23,496] INFO:          weight: 0.5
[2018-05-09 15:34:23,496] INFO: Result
[2018-05-09 15:34:23,496] INFO:      Run     AUC     Shape
[2018-05-09 15:36:24,756] INFO:        1     0.785968     44601 x 54
[2018-05-09 15:38:27,084] INFO:        2     0.803314     44601 x 54
[2018-05-09 15:40:29,159] INFO:        3     0.794135     44602 x 54
[2018-05-09 15:40:29,383] INFO: AUC
[2018-05-09 15:40:29,384] INFO:      cv_mean: 0.794472
[2018-05-09 15:40:29,384] INFO:      cv_test: 0.799948
[2018-05-09 15:40:29,384] INFO: Time
[2018-05-09 15:40:29,384] INFO:      6 mins
[2018-05-09 15:40:29,384] INFO: --------------------------------------------------
[2018-05-09 15:43:36,928] INFO: tpe_transform took 0.007607 seconds
[2018-05-09 15:43:36,929] INFO: TPE using 3/3 trials with best loss -0.800525
[2018-05-09 15:43:38,975] INFO: ==================================================
[2018-05-09 15:43:38,975] INFO: Task
[2018-05-09 15:43:38,975] INFO:      stacking_Learner@EnsembleLearner_Id@4
[2018-05-09 15:43:38,976] INFO: Param
[2018-05-09 15:43:38,976] INFO:      clf_skl_lr:
[2018-05-09 15:43:38,976] INFO:          learner: LogisticRegression(C=33.513553677322896, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 15:43:38,976] INFO:          param:
[2018-05-09 15:43:38,976] INFO:              C: 0.0012960257953340923
[2018-05-09 15:43:38,976] INFO:              penalty: l2
[2018-05-09 15:43:38,976] INFO:              random_state: 42
[2018-05-09 15:43:38,976] INFO:          weight: 1.0
[2018-05-09 15:43:38,976] INFO:      clf_skl_rf:
[2018-05-09 15:43:38,977] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=7, max_features=0.45, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=13, min_samples_split=10,
            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 15:43:38,977] INFO:          param:
[2018-05-09 15:43:38,977] INFO:              max_depth: 6
[2018-05-09 15:43:38,977] INFO:              max_features: 0.7000000000000001
[2018-05-09 15:43:38,977] INFO:              min_samples_leaf: 5
[2018-05-09 15:43:38,977] INFO:              min_samples_split: 12
[2018-05-09 15:43:38,977] INFO:              n_estimators: 640
[2018-05-09 15:43:38,977] INFO:              n_jobs: 8
[2018-05-09 15:43:38,977] INFO:              random_state: 42
[2018-05-09 15:43:38,977] INFO:              verbose: 0
[2018-05-09 15:43:38,977] INFO:          weight: 0.4
[2018-05-09 15:43:38,978] INFO:      clf_xgb_tree:
[2018-05-09 15:43:38,978] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.7696145472542932,
       colsample_bytree=0.7838021821310273, gamma=0.00016706319761478086,
       learning_rate=0.006, max_delta_step=0, max_depth=5,
       min_child_weight=7.645991430490395, missing=None, n_estimators=610,
       nthread=8, objective='binary:logistic',
       reg_alpha=6.366961566352447e-08, reg_lambda=3.1290232860923855e-05,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.8616594078010396)
[2018-05-09 15:43:38,978] INFO:          param:
[2018-05-09 15:43:38,978] INFO:              colsample_bylevel: 0.5040312618559015
[2018-05-09 15:43:38,978] INFO:              colsample_bytree: 0.6812204981312985
[2018-05-09 15:43:38,978] INFO:              gamma: 0.0014285356840106262
[2018-05-09 15:43:38,978] INFO:              learning_rate: 0.06
[2018-05-09 15:43:38,978] INFO:              max_depth: 8
[2018-05-09 15:43:38,978] INFO:              min_child_weight: 16.798728407292646
[2018-05-09 15:43:38,978] INFO:              n_estimators: 410
[2018-05-09 15:43:38,978] INFO:              nthread: 8
[2018-05-09 15:43:38,979] INFO:              reg_alpha: 0.4104672171400636
[2018-05-09 15:43:38,979] INFO:              reg_lambda: 2.9198721471076953e-05
[2018-05-09 15:43:38,979] INFO:              seed: 42
[2018-05-09 15:43:38,979] INFO:              subsample: 0.5847084588779512
[2018-05-09 15:43:38,979] INFO:          weight: 0.4
[2018-05-09 15:43:38,979] INFO: Result
[2018-05-09 15:43:38,979] INFO:      Run     AUC     Shape
[2018-05-09 15:46:06,079] INFO:        1     0.785148     44601 x 54
[2018-05-09 15:48:31,207] INFO:        2     0.801834     44601 x 54
[2018-05-09 15:50:53,813] INFO:        3     0.793415     44602 x 54
[2018-05-09 15:50:54,025] INFO: AUC
[2018-05-09 15:50:54,026] INFO:      cv_mean: 0.793465
[2018-05-09 15:50:54,026] INFO:      cv_test: 0.799972
[2018-05-09 15:50:54,026] INFO: Time
[2018-05-09 15:50:54,026] INFO:      7 mins
[2018-05-09 15:50:54,026] INFO: --------------------------------------------------
[2018-05-09 15:54:38,972] INFO: tpe_transform took 0.009170 seconds
[2018-05-09 15:54:38,972] INFO: TPE using 4/4 trials with best loss -0.800525
[2018-05-09 15:54:40,952] INFO: ==================================================
[2018-05-09 15:54:40,952] INFO: Task
[2018-05-09 15:54:40,952] INFO:      stacking_Learner@EnsembleLearner_Id@5
[2018-05-09 15:54:40,953] INFO: Param
[2018-05-09 15:54:40,953] INFO:      clf_skl_lr:
[2018-05-09 15:54:40,953] INFO:          learner: LogisticRegression(C=0.0012960257953340923, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 15:54:40,953] INFO:          param:
[2018-05-09 15:54:40,953] INFO:              C: 26.277334652868515
[2018-05-09 15:54:40,954] INFO:              penalty: l1
[2018-05-09 15:54:40,954] INFO:              random_state: 42
[2018-05-09 15:54:40,954] INFO:          weight: 1.0
[2018-05-09 15:54:40,954] INFO:      clf_skl_rf:
[2018-05-09 15:54:40,954] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=6, max_features=0.7000000000000001,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=5,
            min_samples_split=12, min_weight_fraction_leaf=0.0,
            n_estimators=640, n_jobs=8, oob_score=False, random_state=42,
            verbose=0, warm_start=False)
[2018-05-09 15:54:40,954] INFO:          param:
[2018-05-09 15:54:40,955] INFO:              max_depth: 2
[2018-05-09 15:54:40,955] INFO:              max_features: 0.55
[2018-05-09 15:54:40,955] INFO:              min_samples_leaf: 7
[2018-05-09 15:54:40,955] INFO:              min_samples_split: 9
[2018-05-09 15:54:40,955] INFO:              n_estimators: 450
[2018-05-09 15:54:40,955] INFO:              n_jobs: 8
[2018-05-09 15:54:40,955] INFO:              random_state: 42
[2018-05-09 15:54:40,955] INFO:              verbose: 0
[2018-05-09 15:54:40,955] INFO:          weight: 0.1
[2018-05-09 15:54:40,955] INFO:      clf_xgb_tree:
[2018-05-09 15:54:40,956] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.5040312618559015,
       colsample_bytree=0.6812204981312985, gamma=0.0014285356840106262,
       learning_rate=0.06, max_delta_step=0, max_depth=8,
       min_child_weight=16.798728407292646, missing=None, n_estimators=410,
       nthread=8, objective='binary:logistic',
       reg_alpha=0.4104672171400636, reg_lambda=2.9198721471076953e-05,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.5847084588779512)
[2018-05-09 15:54:40,956] INFO:          param:
[2018-05-09 15:54:40,956] INFO:              colsample_bylevel: 0.7780371852047818
[2018-05-09 15:54:40,956] INFO:              colsample_bytree: 0.8840013270686928
[2018-05-09 15:54:40,956] INFO:              gamma: 0.0640820330233951
[2018-05-09 15:54:40,956] INFO:              learning_rate: 0.076
[2018-05-09 15:54:40,956] INFO:              max_depth: 4
[2018-05-09 15:54:40,957] INFO:              min_child_weight: 0.7237058663248245
[2018-05-09 15:54:40,957] INFO:              n_estimators: 980
[2018-05-09 15:54:40,957] INFO:              nthread: 8
[2018-05-09 15:54:40,957] INFO:              reg_alpha: 3.930549898802433e-06
[2018-05-09 15:54:40,957] INFO:              reg_lambda: 2.7896930304339286e-05
[2018-05-09 15:54:40,957] INFO:              seed: 42
[2018-05-09 15:54:40,957] INFO:              subsample: 0.8504567432656948
[2018-05-09 15:54:40,957] INFO:          weight: 0.4
[2018-05-09 15:54:40,957] INFO: Result
[2018-05-09 15:54:40,957] INFO:      Run     AUC     Shape
[2018-05-09 15:59:19,844] INFO:        1     0.775234     44601 x 54
[2018-05-09 16:03:28,046] INFO:        2     0.801954     44601 x 54
[2018-05-09 16:08:10,526] INFO:        3     0.790833     44602 x 54
[2018-05-09 16:08:10,762] INFO: AUC
[2018-05-09 16:08:10,762] INFO:      cv_mean: 0.789340
[2018-05-09 16:08:10,763] INFO:      cv_test: 0.797781
[2018-05-09 16:08:10,763] INFO: Time
[2018-05-09 16:08:10,763] INFO:      13 mins
[2018-05-09 16:08:10,763] INFO: --------------------------------------------------
[2018-05-09 16:15:15,668] INFO: tpe_transform took 0.008250 seconds
[2018-05-09 16:15:15,669] INFO: TPE using 5/5 trials with best loss -0.800525
[2018-05-09 16:15:17,723] INFO: ==================================================
[2018-05-09 16:15:17,723] INFO: Task
[2018-05-09 16:15:17,723] INFO:      stacking_Learner@EnsembleLearner_Id@6
[2018-05-09 16:15:17,723] INFO: Param
[2018-05-09 16:15:17,724] INFO:      clf_skl_lr:
[2018-05-09 16:15:17,724] INFO:          learner: LogisticRegression(C=26.277334652868515, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 16:15:17,724] INFO:          param:
[2018-05-09 16:15:17,724] INFO:              C: 2.7977962066883055e-05
[2018-05-09 16:15:17,724] INFO:              penalty: l2
[2018-05-09 16:15:17,724] INFO:              random_state: 42
[2018-05-09 16:15:17,724] INFO:          weight: 1.0
[2018-05-09 16:15:17,724] INFO:      clf_skl_rf:
[2018-05-09 16:15:17,725] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=2, max_features=0.55, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=7, min_samples_split=9,
            min_weight_fraction_leaf=0.0, n_estimators=450, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 16:15:17,725] INFO:          param:
[2018-05-09 16:15:17,725] INFO:              max_depth: 8
[2018-05-09 16:15:17,725] INFO:              max_features: 0.6000000000000001
[2018-05-09 16:15:17,725] INFO:              min_samples_leaf: 10
[2018-05-09 16:15:17,725] INFO:              min_samples_split: 11
[2018-05-09 16:15:17,726] INFO:              n_estimators: 280
[2018-05-09 16:15:17,726] INFO:              n_jobs: 8
[2018-05-09 16:15:17,726] INFO:              random_state: 42
[2018-05-09 16:15:17,726] INFO:              verbose: 0
[2018-05-09 16:15:17,726] INFO:          weight: 0.1
[2018-05-09 16:15:17,726] INFO:      clf_xgb_tree:
[2018-05-09 16:15:17,726] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.7780371852047818,
       colsample_bytree=0.8840013270686928, gamma=0.0640820330233951,
       learning_rate=0.076, max_delta_step=0, max_depth=4,
       min_child_weight=0.7237058663248245, missing=None, n_estimators=980,
       nthread=8, objective='binary:logistic',
       reg_alpha=3.930549898802433e-06, reg_lambda=2.7896930304339286e-05,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.8504567432656948)
[2018-05-09 16:15:17,727] INFO:          param:
[2018-05-09 16:15:17,727] INFO:              colsample_bylevel: 0.5470341615562997
[2018-05-09 16:15:17,727] INFO:              colsample_bytree: 0.6591110788050516
[2018-05-09 16:15:17,727] INFO:              gamma: 5.078088742442243e-05
[2018-05-09 16:15:17,727] INFO:              learning_rate: 0.014
[2018-05-09 16:15:17,727] INFO:              max_depth: 5
[2018-05-09 16:15:17,727] INFO:              min_child_weight: 0.002036228417234126
[2018-05-09 16:15:17,727] INFO:              n_estimators: 710
[2018-05-09 16:15:17,727] INFO:              nthread: 8
[2018-05-09 16:15:17,727] INFO:              reg_alpha: 5.242434619651289e-09
[2018-05-09 16:15:17,728] INFO:              reg_lambda: 4.048846223886502e-05
[2018-05-09 16:15:17,728] INFO:              seed: 42
[2018-05-09 16:15:17,728] INFO:              subsample: 0.8983010709767532
[2018-05-09 16:15:17,728] INFO:          weight: 1.0
[2018-05-09 16:15:17,728] INFO: Result
[2018-05-09 16:15:17,728] INFO:      Run     AUC     Shape
[2018-05-09 16:17:21,378] INFO:        1     0.757526     44601 x 54
[2018-05-09 16:19:22,131] INFO:        2     0.800709     44601 x 54
[2018-05-09 16:21:24,016] INFO:        3     0.793587     44602 x 54
[2018-05-09 16:21:24,219] INFO: AUC
[2018-05-09 16:21:24,219] INFO:      cv_mean: 0.783940
[2018-05-09 16:21:24,219] INFO:      cv_test: 0.797798
[2018-05-09 16:21:24,219] INFO: Time
[2018-05-09 16:21:24,220] INFO:      6 mins
[2018-05-09 16:21:24,220] INFO: --------------------------------------------------
[2018-05-09 16:24:31,122] INFO: tpe_transform took 0.008759 seconds
[2018-05-09 16:24:31,122] INFO: TPE using 6/6 trials with best loss -0.800525
[2018-05-09 16:24:33,139] INFO: ==================================================
[2018-05-09 16:24:33,139] INFO: Task
[2018-05-09 16:24:33,139] INFO:      stacking_Learner@EnsembleLearner_Id@7
[2018-05-09 16:24:33,140] INFO: Param
[2018-05-09 16:24:33,140] INFO:      clf_skl_lr:
[2018-05-09 16:24:33,140] INFO:          learner: LogisticRegression(C=2.7977962066883055e-05, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 16:24:33,140] INFO:          param:
[2018-05-09 16:24:33,140] INFO:              C: 0.19704618987280037
[2018-05-09 16:24:33,140] INFO:              penalty: l1
[2018-05-09 16:24:33,141] INFO:              random_state: 42
[2018-05-09 16:24:33,141] INFO:          weight: 1.0
[2018-05-09 16:24:33,141] INFO:      clf_skl_rf:
[2018-05-09 16:24:33,141] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=8, max_features=0.6000000000000001,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=10,
            min_samples_split=11, min_weight_fraction_leaf=0.0,
            n_estimators=280, n_jobs=8, oob_score=False, random_state=42,
            verbose=0, warm_start=False)
[2018-05-09 16:24:33,141] INFO:          param:
[2018-05-09 16:24:33,141] INFO:              max_depth: 8
[2018-05-09 16:24:33,141] INFO:              max_features: 0.8
[2018-05-09 16:24:33,142] INFO:              min_samples_leaf: 6
[2018-05-09 16:24:33,142] INFO:              min_samples_split: 13
[2018-05-09 16:24:33,142] INFO:              n_estimators: 820
[2018-05-09 16:24:33,142] INFO:              n_jobs: 8
[2018-05-09 16:24:33,142] INFO:              random_state: 42
[2018-05-09 16:24:33,142] INFO:              verbose: 0
[2018-05-09 16:24:33,142] INFO:          weight: 0.7000000000000001
[2018-05-09 16:24:33,142] INFO:      clf_xgb_tree:
[2018-05-09 16:24:33,142] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.5470341615562997,
       colsample_bytree=0.6591110788050516, gamma=5.078088742442243e-05,
       learning_rate=0.014, max_delta_step=0, max_depth=5,
       min_child_weight=0.002036228417234126, missing=None,
       n_estimators=710, nthread=8, objective='binary:logistic',
       reg_alpha=5.242434619651289e-09, reg_lambda=4.048846223886502e-05,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.8983010709767532)
[2018-05-09 16:24:33,143] INFO:          param:
[2018-05-09 16:24:33,143] INFO:              colsample_bylevel: 0.94312649376965
[2018-05-09 16:24:33,143] INFO:              colsample_bytree: 0.5674695381332897
[2018-05-09 16:24:33,143] INFO:              gamma: 2.273931700592367e-07
[2018-05-09 16:24:33,143] INFO:              learning_rate: 0.038
[2018-05-09 16:24:33,143] INFO:              max_depth: 3
[2018-05-09 16:24:33,143] INFO:              min_child_weight: 1.9193017043916636
[2018-05-09 16:24:33,143] INFO:              n_estimators: 800
[2018-05-09 16:24:33,143] INFO:              nthread: 8
[2018-05-09 16:24:33,143] INFO:              reg_alpha: 0.0009465046640854005
[2018-05-09 16:24:33,143] INFO:              reg_lambda: 3.486966289012267e-09
[2018-05-09 16:24:33,143] INFO:              seed: 42
[2018-05-09 16:24:33,144] INFO:              subsample: 0.8606139751754798
[2018-05-09 16:24:33,144] INFO:          weight: 0.2
[2018-05-09 16:24:33,144] INFO: Result
[2018-05-09 16:24:33,144] INFO:      Run     AUC     Shape
[2018-05-09 16:28:52,281] INFO:        1     0.785361     44601 x 54
[2018-05-09 16:33:02,158] INFO:        2     0.803014     44601 x 54
[2018-05-09 16:37:11,207] INFO:        3     0.793683     44602 x 54
[2018-05-09 16:37:11,438] INFO: AUC
[2018-05-09 16:37:11,439] INFO:      cv_mean: 0.794019
[2018-05-09 16:37:11,439] INFO:      cv_test: 0.799971
[2018-05-09 16:37:11,439] INFO: Time
[2018-05-09 16:37:11,439] INFO:      12 mins
[2018-05-09 16:37:11,439] INFO: --------------------------------------------------
[2018-05-09 16:43:49,757] INFO: tpe_transform took 0.010099 seconds
[2018-05-09 16:43:49,758] INFO: TPE using 7/7 trials with best loss -0.800525
[2018-05-09 16:43:51,848] INFO: ==================================================
[2018-05-09 16:43:51,848] INFO: Task
[2018-05-09 16:43:51,848] INFO:      stacking_Learner@EnsembleLearner_Id@8
[2018-05-09 16:43:51,848] INFO: Param
[2018-05-09 16:43:51,848] INFO:      clf_skl_lr:
[2018-05-09 16:43:51,849] INFO:          learner: LogisticRegression(C=0.19704618987280037, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 16:43:51,849] INFO:          param:
[2018-05-09 16:43:51,849] INFO:              C: 0.0007513906357120155
[2018-05-09 16:43:51,849] INFO:              penalty: l2
[2018-05-09 16:43:51,849] INFO:              random_state: 42
[2018-05-09 16:43:51,849] INFO:          weight: 1.0
[2018-05-09 16:43:51,849] INFO:      clf_skl_rf:
[2018-05-09 16:43:51,849] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=8, max_features=0.8, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=6, min_samples_split=13,
            min_weight_fraction_leaf=0.0, n_estimators=820, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 16:43:51,849] INFO:          param:
[2018-05-09 16:43:51,849] INFO:              max_depth: 6
[2018-05-09 16:43:51,850] INFO:              max_features: 0.4
[2018-05-09 16:43:51,850] INFO:              min_samples_leaf: 5
[2018-05-09 16:43:51,850] INFO:              min_samples_split: 6
[2018-05-09 16:43:51,850] INFO:              n_estimators: 470
[2018-05-09 16:43:51,850] INFO:              n_jobs: 8
[2018-05-09 16:43:51,850] INFO:              random_state: 42
[2018-05-09 16:43:51,850] INFO:              verbose: 0
[2018-05-09 16:43:51,850] INFO:          weight: 0.1
[2018-05-09 16:43:51,850] INFO:      clf_xgb_tree:
[2018-05-09 16:43:51,850] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.94312649376965,
       colsample_bytree=0.5674695381332897, gamma=2.273931700592367e-07,
       learning_rate=0.038, max_delta_step=0, max_depth=3,
       min_child_weight=1.9193017043916636, missing=None, n_estimators=800,
       nthread=8, objective='binary:logistic',
       reg_alpha=0.0009465046640854005, reg_lambda=3.486966289012267e-09,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.8606139751754798)
[2018-05-09 16:43:51,850] INFO:          param:
[2018-05-09 16:43:51,851] INFO:              colsample_bylevel: 0.9232692779786056
[2018-05-09 16:43:51,851] INFO:              colsample_bytree: 0.7900481060845375
[2018-05-09 16:43:51,851] INFO:              gamma: 0.020301663796582232
[2018-05-09 16:43:51,851] INFO:              learning_rate: 0.006
[2018-05-09 16:43:51,851] INFO:              max_depth: 3
[2018-05-09 16:43:51,851] INFO:              min_child_weight: 7.2587839235075736e-06
[2018-05-09 16:43:51,851] INFO:              n_estimators: 670
[2018-05-09 16:43:51,851] INFO:              nthread: 8
[2018-05-09 16:43:51,851] INFO:              reg_alpha: 6.234285701599528
[2018-05-09 16:43:51,851] INFO:              reg_lambda: 0.02528484999784429
[2018-05-09 16:43:51,851] INFO:              seed: 42
[2018-05-09 16:43:51,851] INFO:              subsample: 0.5074926846254154
[2018-05-09 16:43:51,851] INFO:          weight: 0.9
[2018-05-09 16:43:51,851] INFO: Result
[2018-05-09 16:43:51,851] INFO:      Run     AUC     Shape
[2018-05-09 16:45:41,886] INFO:        1     0.786532     44601 x 54
[2018-05-09 16:47:29,903] INFO:        2     0.804449     44601 x 54
[2018-05-09 16:49:19,968] INFO:        3      0.79581     44602 x 54
[2018-05-09 16:49:20,189] INFO: AUC
[2018-05-09 16:49:20,189] INFO:      cv_mean: 0.795597
[2018-05-09 16:49:20,189] INFO:      cv_test: 0.800982
[2018-05-09 16:49:20,189] INFO: Time
[2018-05-09 16:49:20,189] INFO:      5 mins
[2018-05-09 16:49:20,189] INFO: --------------------------------------------------
[2018-05-09 16:52:11,807] INFO: tpe_transform took 0.010733 seconds
[2018-05-09 16:52:11,808] INFO: TPE using 8/8 trials with best loss -0.800885
[2018-05-09 16:52:13,915] INFO: ==================================================
[2018-05-09 16:52:13,916] INFO: Task
[2018-05-09 16:52:13,916] INFO:      stacking_Learner@EnsembleLearner_Id@9
[2018-05-09 16:52:13,916] INFO: Param
[2018-05-09 16:52:13,916] INFO:      clf_skl_lr:
[2018-05-09 16:52:13,916] INFO:          learner: LogisticRegression(C=0.0007513906357120155, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 16:52:13,916] INFO:          param:
[2018-05-09 16:52:13,916] INFO:              C: 0.0023026499937874923
[2018-05-09 16:52:13,917] INFO:              penalty: l2
[2018-05-09 16:52:13,917] INFO:              random_state: 42
[2018-05-09 16:52:13,917] INFO:          weight: 1.0
[2018-05-09 16:52:13,917] INFO:      clf_skl_rf:
[2018-05-09 16:52:13,917] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=6, max_features=0.4, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=5, min_samples_split=6,
            min_weight_fraction_leaf=0.0, n_estimators=470, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 16:52:13,917] INFO:          param:
[2018-05-09 16:52:13,917] INFO:              max_depth: 5
[2018-05-09 16:52:13,917] INFO:              max_features: 0.75
[2018-05-09 16:52:13,917] INFO:              min_samples_leaf: 13
[2018-05-09 16:52:13,917] INFO:              min_samples_split: 8
[2018-05-09 16:52:13,917] INFO:              n_estimators: 670
[2018-05-09 16:52:13,918] INFO:              n_jobs: 8
[2018-05-09 16:52:13,918] INFO:              random_state: 42
[2018-05-09 16:52:13,918] INFO:              verbose: 0
[2018-05-09 16:52:13,918] INFO:          weight: 0.9
[2018-05-09 16:52:13,918] INFO:      clf_xgb_tree:
[2018-05-09 16:52:13,918] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.9232692779786056,
       colsample_bytree=0.7900481060845375, gamma=0.020301663796582232,
       learning_rate=0.006, max_delta_step=0, max_depth=3,
       min_child_weight=7.2587839235075736e-06, missing=None,
       n_estimators=670, nthread=8, objective='binary:logistic',
       reg_alpha=6.234285701599528, reg_lambda=0.02528484999784429,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.5074926846254154)
[2018-05-09 16:52:13,919] INFO:          param:
[2018-05-09 16:52:13,919] INFO:              colsample_bylevel: 0.7182162474300497
[2018-05-09 16:52:13,919] INFO:              colsample_bytree: 0.8218791165929212
[2018-05-09 16:52:13,919] INFO:              gamma: 3.872407624212969e-06
[2018-05-09 16:52:13,919] INFO:              learning_rate: 0.01
[2018-05-09 16:52:13,919] INFO:              max_depth: 2
[2018-05-09 16:52:13,920] INFO:              min_child_weight: 0.44440525162781847
[2018-05-09 16:52:13,920] INFO:              n_estimators: 990
[2018-05-09 16:52:13,920] INFO:              nthread: 8
[2018-05-09 16:52:13,920] INFO:              reg_alpha: 0.019520138486204812
[2018-05-09 16:52:13,920] INFO:              reg_lambda: 4.84394544146452e-07
[2018-05-09 16:52:13,920] INFO:              seed: 42
[2018-05-09 16:52:13,920] INFO:              subsample: 0.527157627973496
[2018-05-09 16:52:13,920] INFO:          weight: 0.6000000000000001
[2018-05-09 16:52:13,920] INFO: Result
[2018-05-09 16:52:13,920] INFO:      Run     AUC     Shape
[2018-05-09 16:54:41,252] INFO:        1     0.786234     44601 x 54
[2018-05-09 16:57:04,428] INFO:        2     0.804278     44601 x 54
[2018-05-09 16:59:30,442] INFO:        3     0.795611     44602 x 54
[2018-05-09 16:59:30,658] INFO: AUC
[2018-05-09 16:59:30,658] INFO:      cv_mean: 0.795374
[2018-05-09 16:59:30,658] INFO:      cv_test: 0.800932
[2018-05-09 16:59:30,658] INFO: Time
[2018-05-09 16:59:30,658] INFO:      7 mins
[2018-05-09 16:59:30,658] INFO: --------------------------------------------------
[2018-05-09 17:03:12,797] INFO: Hyperopt_Time
[2018-05-09 17:03:12,798] INFO:      115 mins
[2018-05-09 17:03:12,798] INFO: --------------------------------------------------
