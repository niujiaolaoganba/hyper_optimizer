[2018-05-09 11:06:39,048] INFO: tpe_transform took 0.007467 seconds
[2018-05-09 11:06:39,048] INFO: TPE using 0 trials
[2018-05-09 11:06:39,052] INFO: ==================================================
[2018-05-09 11:06:39,052] INFO: Task
[2018-05-09 11:06:39,052] INFO:      Learner@EnsembleLearner_Id@1
[2018-05-09 11:06:39,052] INFO: Param
[2018-05-09 11:06:39,053] INFO:      clf_skl_lr:
[2018-05-09 11:06:39,053] INFO:          learner: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
[2018-05-09 11:06:39,053] INFO:          param:
[2018-05-09 11:06:39,053] INFO:              C: 1.2328411572923001e-07
[2018-05-09 11:06:39,054] INFO:              penalty: l1
[2018-05-09 11:06:39,054] INFO:              random_state: 42
[2018-05-09 11:06:39,054] INFO:          weight: 1.0
[2018-05-09 11:06:39,054] INFO:      clf_skl_rf:
[2018-05-09 11:06:39,054] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
[2018-05-09 11:06:39,054] INFO:          param:
[2018-05-09 11:06:39,054] INFO:              max_depth: 9
[2018-05-09 11:06:39,054] INFO:              max_features: 0.8500000000000001
[2018-05-09 11:06:39,055] INFO:              min_samples_leaf: 14
[2018-05-09 11:06:39,055] INFO:              min_samples_split: 6
[2018-05-09 11:06:39,055] INFO:              n_estimators: 570
[2018-05-09 11:06:39,055] INFO:              n_jobs: 8
[2018-05-09 11:06:39,055] INFO:              random_state: 42
[2018-05-09 11:06:39,055] INFO:              verbose: 0
[2018-05-09 11:06:39,055] INFO:          weight: 0.30000000000000004
[2018-05-09 11:06:39,055] INFO:      clf_xgb_tree:
[2018-05-09 11:06:39,056] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,
       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,
       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,
       objective='binary:logistic', reg_alpha=0, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=1)
[2018-05-09 11:06:39,056] INFO:          param:
[2018-05-09 11:06:39,056] INFO:              colsample_bylevel: 0.8882728247231527
[2018-05-09 11:06:39,056] INFO:              colsample_bytree: 0.6351407448013191
[2018-05-09 11:06:39,056] INFO:              gamma: 0.2715780447561645
[2018-05-09 11:06:39,056] INFO:              learning_rate: 0.004
[2018-05-09 11:06:39,056] INFO:              max_depth: 6
[2018-05-09 11:06:39,056] INFO:              min_child_weight: 0.22586662479244682
[2018-05-09 11:06:39,057] INFO:              n_estimators: 930
[2018-05-09 11:06:39,057] INFO:              nthread: 8
[2018-05-09 11:06:39,057] INFO:              reg_alpha: 1.5848415628655665e-08
[2018-05-09 11:06:39,057] INFO:              reg_lambda: 0.003656909992425253
[2018-05-09 11:06:39,057] INFO:              seed: 42
[2018-05-09 11:06:39,057] INFO:              subsample: 0.8638971953119792
[2018-05-09 11:06:39,057] INFO:          weight: 0.9
[2018-05-09 11:06:39,057] INFO: Result
[2018-05-09 11:06:39,057] INFO:      Run     AUC     Shape
[2018-05-09 11:15:31,058] INFO:        1     0.781591     44601 x 390
[2018-05-09 11:24:45,358] INFO:        2     0.796541     44601 x 390
[2018-05-09 11:33:45,180] INFO:        3     0.787523     44602 x 390
[2018-05-09 11:33:45,393] INFO: AUC
[2018-05-09 11:33:45,393] INFO:      cv_mean: 0.788552
[2018-05-09 11:33:45,393] INFO:      cv_test: 0.793493
[2018-05-09 11:33:45,393] INFO: Time
[2018-05-09 11:33:45,393] INFO:      27 mins
[2018-05-09 11:33:45,393] INFO: --------------------------------------------------
[2018-05-09 11:48:07,689] INFO: tpe_transform took 0.008203 seconds
[2018-05-09 11:48:07,689] INFO: TPE using 1/1 trials with best loss -0.793607
[2018-05-09 11:48:07,693] INFO: ==================================================
[2018-05-09 11:48:07,693] INFO: Task
[2018-05-09 11:48:07,693] INFO:      Learner@EnsembleLearner_Id@2
[2018-05-09 11:48:07,693] INFO: Param
[2018-05-09 11:48:07,693] INFO:      clf_skl_lr:
[2018-05-09 11:48:07,693] INFO:          learner: LogisticRegression(C=1.2328411572923001e-07, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 11:48:07,693] INFO:          param:
[2018-05-09 11:48:07,694] INFO:              C: 0.0022053406657527768
[2018-05-09 11:48:07,694] INFO:              penalty: l2
[2018-05-09 11:48:07,694] INFO:              random_state: 42
[2018-05-09 11:48:07,694] INFO:          weight: 1.0
[2018-05-09 11:48:07,694] INFO:      clf_skl_rf:
[2018-05-09 11:48:07,694] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=9, max_features=0.8500000000000001,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=14,
            min_samples_split=6, min_weight_fraction_leaf=0.0,
            n_estimators=570, n_jobs=8, oob_score=False, random_state=42,
            verbose=0, warm_start=False)
[2018-05-09 11:48:07,694] INFO:          param:
[2018-05-09 11:48:07,694] INFO:              max_depth: 4
[2018-05-09 11:48:07,694] INFO:              max_features: 0.35000000000000003
[2018-05-09 11:48:07,694] INFO:              min_samples_leaf: 13
[2018-05-09 11:48:07,695] INFO:              min_samples_split: 12
[2018-05-09 11:48:07,695] INFO:              n_estimators: 720
[2018-05-09 11:48:07,695] INFO:              n_jobs: 8
[2018-05-09 11:48:07,695] INFO:              random_state: 42
[2018-05-09 11:48:07,695] INFO:              verbose: 0
[2018-05-09 11:48:07,695] INFO:          weight: 0.0
[2018-05-09 11:48:07,695] INFO:      clf_xgb_tree:
[2018-05-09 11:48:07,695] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.8882728247231527,
       colsample_bytree=0.6351407448013191, gamma=0.2715780447561645,
       learning_rate=0.004, max_delta_step=0, max_depth=6,
       min_child_weight=0.22586662479244682, missing=None,
       n_estimators=930, nthread=8, objective='binary:logistic',
       reg_alpha=1.5848415628655665e-08, reg_lambda=0.003656909992425253,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.8638971953119792)
[2018-05-09 11:48:07,696] INFO:          param:
[2018-05-09 11:48:07,696] INFO:              colsample_bylevel: 0.5438127363293197
[2018-05-09 11:48:07,696] INFO:              colsample_bytree: 0.7159145275093577
[2018-05-09 11:48:07,696] INFO:              gamma: 3.882802666325188e-09
[2018-05-09 11:48:07,696] INFO:              learning_rate: 0.084
[2018-05-09 11:48:07,696] INFO:              max_depth: 4
[2018-05-09 11:48:07,696] INFO:              min_child_weight: 0.004079482115694249
[2018-05-09 11:48:07,696] INFO:              n_estimators: 570
[2018-05-09 11:48:07,696] INFO:              nthread: 8
[2018-05-09 11:48:07,696] INFO:              reg_alpha: 0.35703682248339624
[2018-05-09 11:48:07,696] INFO:              reg_lambda: 3.0604913895894548e-09
[2018-05-09 11:48:07,696] INFO:              seed: 42
[2018-05-09 11:48:07,697] INFO:              subsample: 0.9516741428430351
[2018-05-09 11:48:07,697] INFO:          weight: 0.7000000000000001
[2018-05-09 11:48:07,697] INFO: Result
[2018-05-09 11:48:07,697] INFO:      Run     AUC     Shape
[2018-05-09 11:50:44,119] INFO:        1     0.781502     44601 x 390
[2018-05-09 11:53:20,093] INFO:        2     0.799834     44601 x 390
[2018-05-09 11:55:55,936] INFO:        3     0.793213     44602 x 390
[2018-05-09 11:55:56,176] INFO: AUC
[2018-05-09 11:55:56,176] INFO:      cv_mean: 0.791516
[2018-05-09 11:55:56,176] INFO:      cv_test: 0.799369
[2018-05-09 11:55:56,176] INFO: Time
[2018-05-09 11:55:56,177] INFO:      7 mins
[2018-05-09 11:55:56,177] INFO: --------------------------------------------------
[2018-05-09 12:00:02,143] INFO: tpe_transform took 0.008555 seconds
[2018-05-09 12:00:02,144] INFO: TPE using 2/2 trials with best loss -0.799862
[2018-05-09 12:00:02,147] INFO: ==================================================
[2018-05-09 12:00:02,148] INFO: Task
[2018-05-09 12:00:02,148] INFO:      Learner@EnsembleLearner_Id@3
[2018-05-09 12:00:02,148] INFO: Param
[2018-05-09 12:00:02,148] INFO:      clf_skl_lr:
[2018-05-09 12:00:02,148] INFO:          learner: LogisticRegression(C=0.0022053406657527768, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 12:00:02,148] INFO:          param:
[2018-05-09 12:00:02,148] INFO:              C: 13.613156910744792
[2018-05-09 12:00:02,148] INFO:              penalty: l1
[2018-05-09 12:00:02,148] INFO:              random_state: 42
[2018-05-09 12:00:02,148] INFO:          weight: 1.0
[2018-05-09 12:00:02,149] INFO:      clf_skl_rf:
[2018-05-09 12:00:02,149] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=4, max_features=0.35000000000000003,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=13,
            min_samples_split=12, min_weight_fraction_leaf=0.0,
            n_estimators=720, n_jobs=8, oob_score=False, random_state=42,
            verbose=0, warm_start=False)
[2018-05-09 12:00:02,149] INFO:          param:
[2018-05-09 12:00:02,149] INFO:              max_depth: 2
[2018-05-09 12:00:02,149] INFO:              max_features: 0.75
[2018-05-09 12:00:02,149] INFO:              min_samples_leaf: 6
[2018-05-09 12:00:02,149] INFO:              min_samples_split: 7
[2018-05-09 12:00:02,149] INFO:              n_estimators: 140
[2018-05-09 12:00:02,150] INFO:              n_jobs: 8
[2018-05-09 12:00:02,150] INFO:              random_state: 42
[2018-05-09 12:00:02,150] INFO:              verbose: 0
[2018-05-09 12:00:02,150] INFO:          weight: 0.7000000000000001
[2018-05-09 12:00:02,150] INFO:      clf_xgb_tree:
[2018-05-09 12:00:02,150] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.5438127363293197,
       colsample_bytree=0.7159145275093577, gamma=3.882802666325188e-09,
       learning_rate=0.084, max_delta_step=0, max_depth=4,
       min_child_weight=0.004079482115694249, missing=None,
       n_estimators=570, nthread=8, objective='binary:logistic',
       reg_alpha=0.35703682248339624, reg_lambda=3.0604913895894548e-09,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.9516741428430351)
[2018-05-09 12:00:02,150] INFO:          param:
[2018-05-09 12:00:02,150] INFO:              colsample_bylevel: 0.7898835453644668
[2018-05-09 12:00:02,150] INFO:              colsample_bytree: 0.6315851847907719
[2018-05-09 12:00:02,150] INFO:              gamma: 1.0865613507110112e-06
[2018-05-09 12:00:02,150] INFO:              learning_rate: 0.054
[2018-05-09 12:00:02,151] INFO:              max_depth: 4
[2018-05-09 12:00:02,151] INFO:              min_child_weight: 0.009036275648247298
[2018-05-09 12:00:02,151] INFO:              n_estimators: 470
[2018-05-09 12:00:02,151] INFO:              nthread: 8
[2018-05-09 12:00:02,151] INFO:              reg_alpha: 1.4386209657465105e-07
[2018-05-09 12:00:02,151] INFO:              reg_lambda: 4.762644959343229e-10
[2018-05-09 12:00:02,151] INFO:              seed: 42
[2018-05-09 12:00:02,151] INFO:              subsample: 0.9520914587718132
[2018-05-09 12:00:02,151] INFO:          weight: 0.0
[2018-05-09 12:00:02,151] INFO: Result
[2018-05-09 12:00:02,151] INFO:      Run     AUC     Shape
[2018-05-09 12:02:14,620] INFO:        1      0.77373     44601 x 390
[2018-05-09 12:04:29,598] INFO:        2     0.792281     44601 x 390
[2018-05-09 12:06:49,836] INFO:        3     0.786099     44602 x 390
[2018-05-09 12:06:50,046] INFO: AUC
[2018-05-09 12:06:50,046] INFO:      cv_mean: 0.784037
[2018-05-09 12:06:50,047] INFO:      cv_test: 0.793706
[2018-05-09 12:06:50,047] INFO: Time
[2018-05-09 12:06:50,047] INFO:      6 mins
[2018-05-09 12:06:50,047] INFO: --------------------------------------------------
[2018-05-09 12:10:07,177] INFO: tpe_transform took 0.008664 seconds
[2018-05-09 12:10:07,177] INFO: TPE using 3/3 trials with best loss -0.799862
[2018-05-09 12:10:07,182] INFO: ==================================================
[2018-05-09 12:10:07,182] INFO: Task
[2018-05-09 12:10:07,182] INFO:      Learner@EnsembleLearner_Id@4
[2018-05-09 12:10:07,182] INFO: Param
[2018-05-09 12:10:07,182] INFO:      clf_skl_lr:
[2018-05-09 12:10:07,183] INFO:          learner: LogisticRegression(C=13.613156910744792, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 12:10:07,183] INFO:          param:
[2018-05-09 12:10:07,183] INFO:              C: 1.564499343349835e-06
[2018-05-09 12:10:07,183] INFO:              penalty: l1
[2018-05-09 12:10:07,183] INFO:              random_state: 42
[2018-05-09 12:10:07,183] INFO:          weight: 1.0
[2018-05-09 12:10:07,183] INFO:      clf_skl_rf:
[2018-05-09 12:10:07,184] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=2, max_features=0.75, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=6, min_samples_split=7,
            min_weight_fraction_leaf=0.0, n_estimators=140, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 12:10:07,184] INFO:          param:
[2018-05-09 12:10:07,184] INFO:              max_depth: 7
[2018-05-09 12:10:07,184] INFO:              max_features: 0.45
[2018-05-09 12:10:07,184] INFO:              min_samples_leaf: 6
[2018-05-09 12:10:07,184] INFO:              min_samples_split: 5
[2018-05-09 12:10:07,184] INFO:              n_estimators: 960
[2018-05-09 12:10:07,185] INFO:              n_jobs: 8
[2018-05-09 12:10:07,185] INFO:              random_state: 42
[2018-05-09 12:10:07,185] INFO:              verbose: 0
[2018-05-09 12:10:07,185] INFO:          weight: 0.9
[2018-05-09 12:10:07,185] INFO:      clf_xgb_tree:
[2018-05-09 12:10:07,185] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.7898835453644668,
       colsample_bytree=0.6315851847907719, gamma=1.0865613507110112e-06,
       learning_rate=0.054, max_delta_step=0, max_depth=4,
       min_child_weight=0.009036275648247298, missing=None,
       n_estimators=470, nthread=8, objective='binary:logistic',
       reg_alpha=1.4386209657465105e-07, reg_lambda=4.762644959343229e-10,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.9520914587718132)
[2018-05-09 12:10:07,185] INFO:          param:
[2018-05-09 12:10:07,186] INFO:              colsample_bylevel: 0.9100128405388066
[2018-05-09 12:10:07,186] INFO:              colsample_bytree: 0.6486996820316178
[2018-05-09 12:10:07,186] INFO:              gamma: 1.4832922515844997e-09
[2018-05-09 12:10:07,186] INFO:              learning_rate: 0.004
[2018-05-09 12:10:07,186] INFO:              max_depth: 2
[2018-05-09 12:10:07,186] INFO:              min_child_weight: 5.89585660084
[2018-05-09 12:10:07,186] INFO:              n_estimators: 160
[2018-05-09 12:10:07,186] INFO:              nthread: 8
[2018-05-09 12:10:07,186] INFO:              reg_alpha: 2.1819545327029485e-08
[2018-05-09 12:10:07,187] INFO:              reg_lambda: 1.1640473124974092e-08
[2018-05-09 12:10:07,187] INFO:              seed: 42
[2018-05-09 12:10:07,187] INFO:              subsample: 0.7279151256559127
[2018-05-09 12:10:07,187] INFO:          weight: 0.6000000000000001
[2018-05-09 12:10:07,187] INFO: Result
[2018-05-09 12:10:07,187] INFO:      Run     AUC     Shape
[2018-05-09 12:12:41,039] INFO:        1     0.770895     44601 x 390
[2018-05-09 12:15:17,468] INFO:        2     0.787355     44601 x 390
[2018-05-09 12:17:55,786] INFO:        3     0.779297     44602 x 390
[2018-05-09 12:17:56,019] INFO: AUC
[2018-05-09 12:17:56,020] INFO:      cv_mean: 0.779182
[2018-05-09 12:17:56,020] INFO:      cv_test: 0.786357
[2018-05-09 12:17:56,020] INFO: Time
[2018-05-09 12:17:56,020] INFO:      7 mins
[2018-05-09 12:17:56,020] INFO: --------------------------------------------------
[2018-05-09 12:22:23,818] INFO: tpe_transform took 0.010072 seconds
[2018-05-09 12:22:23,818] INFO: TPE using 4/4 trials with best loss -0.799862
[2018-05-09 12:22:23,821] INFO: ==================================================
[2018-05-09 12:22:23,821] INFO: Task
[2018-05-09 12:22:23,821] INFO:      Learner@EnsembleLearner_Id@5
[2018-05-09 12:22:23,822] INFO: Param
[2018-05-09 12:22:23,822] INFO:      clf_skl_lr:
[2018-05-09 12:22:23,822] INFO:          learner: LogisticRegression(C=1.564499343349835e-06, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 12:22:23,823] INFO:          param:
[2018-05-09 12:22:23,823] INFO:              C: 28.185980345795638
[2018-05-09 12:22:23,823] INFO:              penalty: l1
[2018-05-09 12:22:23,823] INFO:              random_state: 42
[2018-05-09 12:22:23,823] INFO:          weight: 1.0
[2018-05-09 12:22:23,823] INFO:      clf_skl_rf:
[2018-05-09 12:22:23,824] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=7, max_features=0.45, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=6, min_samples_split=5,
            min_weight_fraction_leaf=0.0, n_estimators=960, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 12:22:23,824] INFO:          param:
[2018-05-09 12:22:23,824] INFO:              max_depth: 3
[2018-05-09 12:22:23,824] INFO:              max_features: 0.5
[2018-05-09 12:22:23,824] INFO:              min_samples_leaf: 5
[2018-05-09 12:22:23,825] INFO:              min_samples_split: 13
[2018-05-09 12:22:23,825] INFO:              n_estimators: 210
[2018-05-09 12:22:23,825] INFO:              n_jobs: 8
[2018-05-09 12:22:23,825] INFO:              random_state: 42
[2018-05-09 12:22:23,825] INFO:              verbose: 0
[2018-05-09 12:22:23,825] INFO:          weight: 0.7000000000000001
[2018-05-09 12:22:23,825] INFO:      clf_xgb_tree:
[2018-05-09 12:22:23,826] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.9100128405388066,
       colsample_bytree=0.6486996820316178, gamma=1.4832922515844997e-09,
       learning_rate=0.004, max_delta_step=0, max_depth=2,
       min_child_weight=5.89585660084, missing=None, n_estimators=160,
       nthread=8, objective='binary:logistic',
       reg_alpha=2.1819545327029485e-08, reg_lambda=1.1640473124974092e-08,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.7279151256559127)
[2018-05-09 12:22:23,826] INFO:          param:
[2018-05-09 12:22:23,826] INFO:              colsample_bylevel: 0.9721517144650165
[2018-05-09 12:22:23,826] INFO:              colsample_bytree: 0.7056860513310392
[2018-05-09 12:22:23,826] INFO:              gamma: 5.963764930388832e-06
[2018-05-09 12:22:23,826] INFO:              learning_rate: 0.044
[2018-05-09 12:22:23,826] INFO:              max_depth: 7
[2018-05-09 12:22:23,826] INFO:              min_child_weight: 0.05744467490308766
[2018-05-09 12:22:23,827] INFO:              n_estimators: 760
[2018-05-09 12:22:23,827] INFO:              nthread: 8
[2018-05-09 12:22:23,827] INFO:              reg_alpha: 0.004454562197541425
[2018-05-09 12:22:23,827] INFO:              reg_lambda: 1.2824967884035362e-10
[2018-05-09 12:22:23,827] INFO:              seed: 42
[2018-05-09 12:22:23,827] INFO:              subsample: 0.7281273013879656
[2018-05-09 12:22:23,827] INFO:          weight: 0.30000000000000004
[2018-05-09 12:22:23,827] INFO: Result
[2018-05-09 12:22:23,827] INFO:      Run     AUC     Shape
[2018-05-09 12:30:35,720] INFO:        1     0.779153     44601 x 390
[2018-05-09 12:37:21,406] INFO:        2     0.797519     44601 x 390
[2018-05-09 12:44:13,637] INFO:        3     0.790783     44602 x 390
[2018-05-09 12:44:13,854] INFO: AUC
[2018-05-09 12:44:13,854] INFO:      cv_mean: 0.789152
[2018-05-09 12:44:13,854] INFO:      cv_test: 0.797377
[2018-05-09 12:44:13,854] INFO: Time
[2018-05-09 12:44:13,854] INFO:      21 mins
[2018-05-09 12:44:13,854] INFO: --------------------------------------------------
[2018-05-09 12:56:39,318] INFO: tpe_transform took 0.009182 seconds
[2018-05-09 12:56:39,318] INFO: TPE using 5/5 trials with best loss -0.799862
[2018-05-09 12:56:39,322] INFO: ==================================================
[2018-05-09 12:56:39,322] INFO: Task
[2018-05-09 12:56:39,322] INFO:      Learner@EnsembleLearner_Id@6
[2018-05-09 12:56:39,322] INFO: Param
[2018-05-09 12:56:39,322] INFO:      clf_skl_lr:
[2018-05-09 12:56:39,323] INFO:          learner: LogisticRegression(C=28.185980345795638, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 12:56:39,323] INFO:          param:
[2018-05-09 12:56:39,323] INFO:              C: 1.6229455779587498e-06
[2018-05-09 12:56:39,323] INFO:              penalty: l1
[2018-05-09 12:56:39,323] INFO:              random_state: 42
[2018-05-09 12:56:39,323] INFO:          weight: 1.0
[2018-05-09 12:56:39,323] INFO:      clf_skl_rf:
[2018-05-09 12:56:39,324] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=3, max_features=0.5, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=5, min_samples_split=13,
            min_weight_fraction_leaf=0.0, n_estimators=210, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 12:56:39,324] INFO:          param:
[2018-05-09 12:56:39,324] INFO:              max_depth: 7
[2018-05-09 12:56:39,324] INFO:              max_features: 0.75
[2018-05-09 12:56:39,325] INFO:              min_samples_leaf: 13
[2018-05-09 12:56:39,325] INFO:              min_samples_split: 10
[2018-05-09 12:56:39,325] INFO:              n_estimators: 900
[2018-05-09 12:56:39,325] INFO:              n_jobs: 8
[2018-05-09 12:56:39,325] INFO:              random_state: 42
[2018-05-09 12:56:39,325] INFO:              verbose: 0
[2018-05-09 12:56:39,325] INFO:          weight: 0.2
[2018-05-09 12:56:39,325] INFO:      clf_xgb_tree:
[2018-05-09 12:56:39,326] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.9721517144650165,
       colsample_bytree=0.7056860513310392, gamma=5.963764930388832e-06,
       learning_rate=0.044, max_delta_step=0, max_depth=7,
       min_child_weight=0.05744467490308766, missing=None,
       n_estimators=760, nthread=8, objective='binary:logistic',
       reg_alpha=0.004454562197541425, reg_lambda=1.2824967884035362e-10,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.7281273013879656)
[2018-05-09 12:56:39,326] INFO:          param:
[2018-05-09 12:56:39,326] INFO:              colsample_bylevel: 0.5364996965762565
[2018-05-09 12:56:39,326] INFO:              colsample_bytree: 0.8878313339827455
[2018-05-09 12:56:39,326] INFO:              gamma: 0.0017429744538261733
[2018-05-09 12:56:39,326] INFO:              learning_rate: 0.03
[2018-05-09 12:56:39,326] INFO:              max_depth: 6
[2018-05-09 12:56:39,327] INFO:              min_child_weight: 0.06183584635338659
[2018-05-09 12:56:39,327] INFO:              n_estimators: 160
[2018-05-09 12:56:39,327] INFO:              nthread: 8
[2018-05-09 12:56:39,327] INFO:              reg_alpha: 0.021563607760751537
[2018-05-09 12:56:39,327] INFO:              reg_lambda: 2.772115895974931e-10
[2018-05-09 12:56:39,327] INFO:              seed: 42
[2018-05-09 12:56:39,327] INFO:              subsample: 0.6802327503009675
[2018-05-09 12:56:39,327] INFO:          weight: 0.30000000000000004
[2018-05-09 12:56:39,327] INFO: Result
[2018-05-09 12:56:39,327] INFO:      Run     AUC     Shape
[2018-05-09 13:01:03,043] INFO:        1     0.781403     44601 x 390
[2018-05-09 13:05:27,867] INFO:        2     0.797111     44601 x 390
[2018-05-09 13:09:57,888] INFO:        3     0.787685     44602 x 390
[2018-05-09 13:09:58,101] INFO: AUC
[2018-05-09 13:09:58,101] INFO:      cv_mean: 0.788733
[2018-05-09 13:09:58,101] INFO:      cv_test: 0.793900
[2018-05-09 13:09:58,101] INFO: Time
[2018-05-09 13:09:58,101] INFO:      13 mins
[2018-05-09 13:09:58,101] INFO: --------------------------------------------------
[2018-05-09 13:17:13,129] INFO: tpe_transform took 0.006918 seconds
[2018-05-09 13:17:13,129] INFO: TPE using 6/6 trials with best loss -0.799862
[2018-05-09 13:17:13,132] INFO: ==================================================
[2018-05-09 13:17:13,132] INFO: Task
[2018-05-09 13:17:13,132] INFO:      Learner@EnsembleLearner_Id@7
[2018-05-09 13:17:13,132] INFO: Param
[2018-05-09 13:17:13,132] INFO:      clf_skl_lr:
[2018-05-09 13:17:13,132] INFO:          learner: LogisticRegression(C=1.6229455779587498e-06, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 13:17:13,132] INFO:          param:
[2018-05-09 13:17:13,132] INFO:              C: 1.4364608193159532e-06
[2018-05-09 13:17:13,132] INFO:              penalty: l1
[2018-05-09 13:17:13,133] INFO:              random_state: 42
[2018-05-09 13:17:13,133] INFO:          weight: 1.0
[2018-05-09 13:17:13,133] INFO:      clf_skl_rf:
[2018-05-09 13:17:13,133] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=7, max_features=0.75, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=13, min_samples_split=10,
            min_weight_fraction_leaf=0.0, n_estimators=900, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 13:17:13,133] INFO:          param:
[2018-05-09 13:17:13,133] INFO:              max_depth: 3
[2018-05-09 13:17:13,133] INFO:              max_features: 0.75
[2018-05-09 13:17:13,133] INFO:              min_samples_leaf: 14
[2018-05-09 13:17:13,133] INFO:              min_samples_split: 8
[2018-05-09 13:17:13,133] INFO:              n_estimators: 200
[2018-05-09 13:17:13,133] INFO:              n_jobs: 8
[2018-05-09 13:17:13,134] INFO:              random_state: 42
[2018-05-09 13:17:13,134] INFO:              verbose: 0
[2018-05-09 13:17:13,134] INFO:          weight: 0.2
[2018-05-09 13:17:13,134] INFO:      clf_xgb_tree:
[2018-05-09 13:17:13,134] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.5364996965762565,
       colsample_bytree=0.8878313339827455, gamma=0.0017429744538261733,
       learning_rate=0.03, max_delta_step=0, max_depth=6,
       min_child_weight=0.06183584635338659, missing=None,
       n_estimators=160, nthread=8, objective='binary:logistic',
       reg_alpha=0.021563607760751537, reg_lambda=2.772115895974931e-10,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.6802327503009675)
[2018-05-09 13:17:13,134] INFO:          param:
[2018-05-09 13:17:13,134] INFO:              colsample_bylevel: 0.9926813233048042
[2018-05-09 13:17:13,134] INFO:              colsample_bytree: 0.8168748464689236
[2018-05-09 13:17:13,134] INFO:              gamma: 1.6823993625428684e-10
[2018-05-09 13:17:13,134] INFO:              learning_rate: 0.006
[2018-05-09 13:17:13,134] INFO:              max_depth: 2
[2018-05-09 13:17:13,135] INFO:              min_child_weight: 1.5392719475328992e-07
[2018-05-09 13:17:13,135] INFO:              n_estimators: 290
[2018-05-09 13:17:13,135] INFO:              nthread: 8
[2018-05-09 13:17:13,135] INFO:              reg_alpha: 9.443647005031225e-07
[2018-05-09 13:17:13,135] INFO:              reg_lambda: 0.2768325822197102
[2018-05-09 13:17:13,135] INFO:              seed: 42
[2018-05-09 13:17:13,135] INFO:              subsample: 0.5857798394082634
[2018-05-09 13:17:13,135] INFO:          weight: 0.5
[2018-05-09 13:17:13,135] INFO: Result
[2018-05-09 13:17:13,135] INFO:      Run     AUC     Shape
[2018-05-09 13:18:38,129] INFO:        1      0.75298     44601 x 390
[2018-05-09 13:20:04,037] INFO:        2     0.771415     44601 x 390
[2018-05-09 13:21:30,149] INFO:        3     0.762466     44602 x 390
[2018-05-09 13:21:30,333] INFO: AUC
[2018-05-09 13:21:30,333] INFO:      cv_mean: 0.762287
[2018-05-09 13:21:30,333] INFO:      cv_test: 0.771152
[2018-05-09 13:21:30,333] INFO: Time
[2018-05-09 13:21:30,333] INFO:      4 mins
[2018-05-09 13:21:30,333] INFO: --------------------------------------------------
[2018-05-09 13:23:45,582] INFO: tpe_transform took 0.007495 seconds
[2018-05-09 13:23:45,582] INFO: TPE using 7/7 trials with best loss -0.799862
[2018-05-09 13:23:45,585] INFO: ==================================================
[2018-05-09 13:23:45,585] INFO: Task
[2018-05-09 13:23:45,586] INFO:      Learner@EnsembleLearner_Id@8
[2018-05-09 13:23:45,586] INFO: Param
[2018-05-09 13:23:45,586] INFO:      clf_skl_lr:
[2018-05-09 13:23:45,586] INFO:          learner: LogisticRegression(C=1.4364608193159532e-06, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 13:23:45,586] INFO:          param:
[2018-05-09 13:23:45,586] INFO:              C: 3.7326665749169913e-07
[2018-05-09 13:23:45,586] INFO:              penalty: l1
[2018-05-09 13:23:45,586] INFO:              random_state: 42
[2018-05-09 13:23:45,586] INFO:          weight: 1.0
[2018-05-09 13:23:45,586] INFO:      clf_skl_rf:
[2018-05-09 13:23:45,587] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=3, max_features=0.75, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=14, min_samples_split=8,
            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 13:23:45,587] INFO:          param:
[2018-05-09 13:23:45,587] INFO:              max_depth: 2
[2018-05-09 13:23:45,587] INFO:              max_features: 0.55
[2018-05-09 13:23:45,587] INFO:              min_samples_leaf: 12
[2018-05-09 13:23:45,587] INFO:              min_samples_split: 15
[2018-05-09 13:23:45,587] INFO:              n_estimators: 800
[2018-05-09 13:23:45,587] INFO:              n_jobs: 8
[2018-05-09 13:23:45,587] INFO:              random_state: 42
[2018-05-09 13:23:45,587] INFO:              verbose: 0
[2018-05-09 13:23:45,587] INFO:          weight: 1.0
[2018-05-09 13:23:45,588] INFO:      clf_xgb_tree:
[2018-05-09 13:23:45,588] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.9926813233048042,
       colsample_bytree=0.8168748464689236, gamma=1.6823993625428684e-10,
       learning_rate=0.006, max_delta_step=0, max_depth=2,
       min_child_weight=1.5392719475328992e-07, missing=None,
       n_estimators=290, nthread=8, objective='binary:logistic',
       reg_alpha=9.443647005031225e-07, reg_lambda=0.2768325822197102,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.5857798394082634)
[2018-05-09 13:23:45,588] INFO:          param:
[2018-05-09 13:23:45,588] INFO:              colsample_bylevel: 0.9223411626415066
[2018-05-09 13:23:45,588] INFO:              colsample_bytree: 0.5439518205995564
[2018-05-09 13:23:45,588] INFO:              gamma: 1.112034671320126e-09
[2018-05-09 13:23:45,588] INFO:              learning_rate: 0.064
[2018-05-09 13:23:45,588] INFO:              max_depth: 7
[2018-05-09 13:23:45,588] INFO:              min_child_weight: 0.05059099505074545
[2018-05-09 13:23:45,588] INFO:              n_estimators: 400
[2018-05-09 13:23:45,588] INFO:              nthread: 8
[2018-05-09 13:23:45,589] INFO:              reg_alpha: 0.46487080614895593
[2018-05-09 13:23:45,589] INFO:              reg_lambda: 5.629956372686456e-09
[2018-05-09 13:23:45,589] INFO:              seed: 42
[2018-05-09 13:23:45,589] INFO:              subsample: 0.7604124452983692
[2018-05-09 13:23:45,589] INFO:          weight: 0.8
[2018-05-09 13:23:45,589] INFO: Result
[2018-05-09 13:23:45,589] INFO:      Run     AUC     Shape
[2018-05-09 13:27:25,468] INFO:        1     0.775726     44601 x 390
[2018-05-09 13:31:06,455] INFO:        2     0.794243     44601 x 390
[2018-05-09 13:34:52,340] INFO:        3     0.787769     44602 x 390
[2018-05-09 13:34:52,574] INFO: AUC
[2018-05-09 13:34:52,574] INFO:      cv_mean: 0.785913
[2018-05-09 13:34:52,574] INFO:      cv_test: 0.796057
[2018-05-09 13:34:52,574] INFO: Time
[2018-05-09 13:34:52,574] INFO:      11 mins
[2018-05-09 13:34:52,574] INFO: --------------------------------------------------
[2018-05-09 13:40:34,904] INFO: tpe_transform took 0.008830 seconds
[2018-05-09 13:40:34,905] INFO: TPE using 8/8 trials with best loss -0.799862
[2018-05-09 13:40:34,908] INFO: ==================================================
[2018-05-09 13:40:34,909] INFO: Task
[2018-05-09 13:40:34,909] INFO:      Learner@EnsembleLearner_Id@9
[2018-05-09 13:40:34,909] INFO: Param
[2018-05-09 13:40:34,909] INFO:      clf_skl_lr:
[2018-05-09 13:40:34,909] INFO:          learner: LogisticRegression(C=3.7326665749169913e-07, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 13:40:34,909] INFO:          param:
[2018-05-09 13:40:34,909] INFO:              C: 3.5968020458984277e-06
[2018-05-09 13:40:34,909] INFO:              penalty: l2
[2018-05-09 13:40:34,909] INFO:              random_state: 42
[2018-05-09 13:40:34,910] INFO:          weight: 1.0
[2018-05-09 13:40:34,910] INFO:      clf_skl_rf:
[2018-05-09 13:40:34,910] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=2, max_features=0.55, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=12, min_samples_split=15,
            min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=8,
            oob_score=False, random_state=42, verbose=0, warm_start=False)
[2018-05-09 13:40:34,910] INFO:          param:
[2018-05-09 13:40:34,910] INFO:              max_depth: 5
[2018-05-09 13:40:34,910] INFO:              max_features: 0.30000000000000004
[2018-05-09 13:40:34,910] INFO:              min_samples_leaf: 10
[2018-05-09 13:40:34,911] INFO:              min_samples_split: 8
[2018-05-09 13:40:34,911] INFO:              n_estimators: 980
[2018-05-09 13:40:34,911] INFO:              n_jobs: 8
[2018-05-09 13:40:34,911] INFO:              random_state: 42
[2018-05-09 13:40:34,911] INFO:              verbose: 0
[2018-05-09 13:40:34,911] INFO:          weight: 0.7000000000000001
[2018-05-09 13:40:34,911] INFO:      clf_xgb_tree:
[2018-05-09 13:40:34,911] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.9223411626415066,
       colsample_bytree=0.5439518205995564, gamma=1.112034671320126e-09,
       learning_rate=0.064, max_delta_step=0, max_depth=7,
       min_child_weight=0.05059099505074545, missing=None,
       n_estimators=400, nthread=8, objective='binary:logistic',
       reg_alpha=0.46487080614895593, reg_lambda=5.629956372686456e-09,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.7604124452983692)
[2018-05-09 13:40:34,912] INFO:          param:
[2018-05-09 13:40:34,912] INFO:              colsample_bylevel: 0.5396627743771909
[2018-05-09 13:40:34,912] INFO:              colsample_bytree: 0.7415625074248084
[2018-05-09 13:40:34,912] INFO:              gamma: 0.8970306326527139
[2018-05-09 13:40:34,912] INFO:              learning_rate: 0.06
[2018-05-09 13:40:34,912] INFO:              max_depth: 2
[2018-05-09 13:40:34,913] INFO:              min_child_weight: 0.0008410210527472222
[2018-05-09 13:40:34,913] INFO:              n_estimators: 330
[2018-05-09 13:40:34,913] INFO:              nthread: 8
[2018-05-09 13:40:34,913] INFO:              reg_alpha: 0.00043807657083657557
[2018-05-09 13:40:34,913] INFO:              reg_lambda: 7.988755966736581e-06
[2018-05-09 13:40:34,913] INFO:              seed: 42
[2018-05-09 13:40:34,913] INFO:              subsample: 0.6615534656977893
[2018-05-09 13:40:34,913] INFO:          weight: 0.6000000000000001
[2018-05-09 13:40:34,913] INFO: Result
[2018-05-09 13:40:34,913] INFO:      Run     AUC     Shape
[2018-05-09 13:42:25,821] INFO:        1     0.757058     44601 x 390
[2018-05-09 13:44:16,973] INFO:        2     0.779409     44601 x 390
[2018-05-09 13:46:08,248] INFO:        3     0.773982     44602 x 390
[2018-05-09 13:46:08,446] INFO: AUC
[2018-05-09 13:46:08,446] INFO:      cv_mean: 0.770150
[2018-05-09 13:46:08,446] INFO:      cv_test: 0.774857
[2018-05-09 13:46:08,447] INFO: Time
[2018-05-09 13:46:08,447] INFO:      5 mins
[2018-05-09 13:46:08,447] INFO: --------------------------------------------------
[2018-05-09 13:49:09,492] INFO: Hyperopt_Time
[2018-05-09 13:49:09,493] INFO:      162 mins
[2018-05-09 13:49:09,493] INFO: --------------------------------------------------
[2018-05-09 13:49:09,521] INFO: tpe_transform took 0.007809 seconds
[2018-05-09 13:49:09,521] INFO: TPE using 0 trials
[2018-05-09 13:49:11,568] INFO: ==================================================
[2018-05-09 13:49:11,568] INFO: Task
[2018-05-09 13:49:11,568] INFO:      Learner@EnsembleLearner_Id@10
[2018-05-09 13:49:11,568] INFO: Param
[2018-05-09 13:49:11,568] INFO:      clf_skl_lr:
[2018-05-09 13:49:11,569] INFO:          learner: LogisticRegression(C=3.5968020458984277e-06, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
[2018-05-09 13:49:11,569] INFO:          param:
[2018-05-09 13:49:11,569] INFO:              C: 32.37138862818074
[2018-05-09 13:49:11,569] INFO:              penalty: l2
[2018-05-09 13:49:11,569] INFO:              random_state: 42
[2018-05-09 13:49:11,569] INFO:          weight: 1.0
[2018-05-09 13:49:11,569] INFO:      clf_skl_rf:
[2018-05-09 13:49:11,570] INFO:          learner: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features=0.30000000000000004,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=10,
            min_samples_split=8, min_weight_fraction_leaf=0.0,
            n_estimators=980, n_jobs=8, oob_score=False, random_state=42,
            verbose=0, warm_start=False)
[2018-05-09 13:49:11,570] INFO:          param:
[2018-05-09 13:49:11,570] INFO:              max_depth: 4
[2018-05-09 13:49:11,570] INFO:              max_features: 0.8
[2018-05-09 13:49:11,570] INFO:              min_samples_leaf: 9
[2018-05-09 13:49:11,570] INFO:              min_samples_split: 7
[2018-05-09 13:49:11,570] INFO:              n_estimators: 780
[2018-05-09 13:49:11,571] INFO:              n_jobs: 8
[2018-05-09 13:49:11,571] INFO:              random_state: 42
[2018-05-09 13:49:11,571] INFO:              verbose: 0
[2018-05-09 13:49:11,571] INFO:          weight: 0.7000000000000001
[2018-05-09 13:49:11,571] INFO:      clf_xgb_tree:
[2018-05-09 13:49:11,571] INFO:          learner: XGBClassifier(base_score=0.5, colsample_bylevel=0.5396627743771909,
       colsample_bytree=0.7415625074248084, gamma=0.8970306326527139,
       learning_rate=0.06, max_delta_step=0, max_depth=2,
       min_child_weight=0.0008410210527472222, missing=None,
       n_estimators=330, nthread=8, objective='binary:logistic',
       reg_alpha=0.00043807657083657557, reg_lambda=7.988755966736581e-06,
       scale_pos_weight=1, seed=42, silent=True,
       subsample=0.6615534656977893)
[2018-05-09 13:49:11,571] INFO:          param:
[2018-05-09 13:49:11,572] INFO:              colsample_bylevel: 0.506285068576233
[2018-05-09 13:49:11,572] INFO:              colsample_bytree: 0.7085274912964932
[2018-05-09 13:49:11,572] INFO:              gamma: 1.8656337920561134e-09
[2018-05-09 13:49:11,572] INFO:              learning_rate: 0.002
[2018-05-09 13:49:11,572] INFO:              max_depth: 9
[2018-05-09 13:49:11,572] INFO:              min_child_weight: 0.003508613227340953
[2018-05-09 13:49:11,572] INFO:              n_estimators: 460
[2018-05-09 13:49:11,572] INFO:              nthread: 8
[2018-05-09 13:49:11,572] INFO:              reg_alpha: 7.484450425769162e-05
[2018-05-09 13:49:11,573] INFO:              reg_lambda: 5.564475172763592e-08
[2018-05-09 13:49:11,573] INFO:              seed: 42
[2018-05-09 13:49:11,573] INFO:              subsample: 0.5892832303699349
[2018-05-09 13:49:11,573] INFO:          weight: 0.0
[2018-05-09 13:49:11,573] INFO: Result
[2018-05-09 13:49:11,573] INFO:      Run     AUC     Shape
[2018-05-09 13:52:01,502] INFO: job exception: feature_names mismatch: ['Learner@clf_lgb_tree_Id@18', 'Learner@clf_skl_rf_Id@7', 'Learner@clf_skl_rf_Id@1', 'Learner@clf_xgb_tree_Id@17', 'Learner@clf_cbst_tree_Id@21', 'Learner@clf_cbst_tree_Id@23', 'Learner@clf_cbst_tree_Id@19', 'Learner@clf_skl_rf_Id@2', 'Learner@clf_cbst_tree_Id@20', 'Learner@clf_xgb_tree_Id@12', 'Learner@clf_skl_lr_Id@9', 'Learner@clf_xgb_tree_Id@14', 'Learner@clf_skl_rf_Id@4', 'Learner@EnsembleLearner_Id@5', 'Learner@clf_xgb_tree_Id@18', 'Learner@clf_skl_lr_Id@8', 'Learner@clf_lgb_tree_Id@13', 'Learner@clf_skl_rf_Id@6', 'Learner@clf_cbst_tree_Id@24', 'Learner@EnsembleLearner_Id@3', 'Learner@clf_cbst_tree_Id@27', 'Learner@clf_cbst_tree_Id@26', 'Learner@clf_lgb_tree_Id@17', 'Learner@clf_xgb_tree_Id@13', 'Learner@clf_skl_lr_Id@7', 'Learner@clf_skl_rf_Id@8', 'Learner@clf_lgb_tree_Id@14', 'Learner@clf_lgb_tree_Id@15', 'Learner@clf_xgb_tree_Id@16', 'Learner@clf_skl_lr_Id@6', 'Learner@EnsembleLearner_Id@1', 'Learner@EnsembleLearner_Id@7', 'Learner@clf_skl_lr_Id@4', 'Learner@EnsembleLearner_Id@8', 'Learner@clf_skl_lr_Id@5', 'Learner@EnsembleLearner_Id@6', 'Learner@clf_cbst_tree_Id@25', 'Learner@clf_lgb_tree_Id@11', 'Learner@EnsembleLearner_Id@2', 'Learner@clf_skl_rf_Id@5', 'Learner@clf_skl_rf_Id@9', 'Learner@EnsembleLearner_Id@4', 'Learner@clf_skl_rf_Id@3', 'Learner@clf_lgb_tree_Id@16', 'Learner@clf_skl_lr_Id@2', 'Learner@clf_xgb_tree_Id@10', 'Learner@clf_skl_lr_Id@3', 'Learner@clf_lgb_tree_Id@10', 'Learner@clf_xgb_tree_Id@15', 'Learner@clf_cbst_tree_Id@22', 'Learner@EnsembleLearner_Id@9', 'Learner@clf_skl_lr_Id@1', 'Learner@clf_lgb_tree_Id@12', 'Learner@clf_xgb_tree_Id@11'] ['Learner@clf_skl_rf_Id@6', 'Learner@clf_cbst_tree_Id@20', 'Learner@clf_xgb_tree_Id@10', 'Learner@clf_lgb_tree_Id@10', 'Learner@clf_xgb_tree_Id@15', 'Learner@clf_cbst_tree_Id@23', 'Learner@clf_cbst_tree_Id@21', 'Learner@clf_lgb_tree_Id@12', 'Learner@clf_cbst_tree_Id@19', 'Learner@clf_xgb_tree_Id@11', 'Learner@clf_lgb_tree_Id@16', 'Learner@clf_skl_lr_Id@9', 'Learner@clf_skl_rf_Id@4', 'Learner@clf_skl_lr_Id@8', 'Learner@clf_lgb_tree_Id@11', 'Learner@clf_skl_rf_Id@2', 'Learner@EnsembleLearner_Id@3', 'Learner@clf_cbst_tree_Id@24', 'Learner@clf_cbst_tree_Id@26', 'Learner@clf_cbst_tree_Id@27', 'Learner@clf_xgb_tree_Id@13', 'Learner@clf_lgb_tree_Id@14', 'Learner@clf_xgb_tree_Id@16', 'Learner@clf_lgb_tree_Id@15', 'Learner@EnsembleLearner_Id@5', 'Learner@clf_skl_rf_Id@7', 'Learner@clf_skl_rf_Id@1', 'Learner@clf_lgb_tree_Id@13', 'Learner@clf_skl_lr_Id@2', 'Learner@EnsembleLearner_Id@2', 'Learner@clf_skl_lr_Id@3', 'Learner@clf_skl_lr_Id@1', 'Learner@EnsembleLearner_Id@4', 'Learner@clf_lgb_tree_Id@17', 'Learner@EnsembleLearner_Id@1', 'Learner@clf_cbst_tree_Id@25', 'Learner@clf_skl_rf_Id@3', 'Learner@EnsembleLearner_Id@6', 'Learner@clf_xgb_tree_Id@14', 'Learner@EnsembleLearner_Id@8', 'Learner@clf_xgb_tree_Id@18', 'Learner@EnsembleLearner_Id@7', 'Learner@clf_cbst_tree_Id@22', 'Learner@clf_skl_rf_Id@5', 'Learner@EnsembleLearner_Id@9', 'Learner@clf_skl_rf_Id@9', 'Learner@clf_xgb_tree_Id@12', 'Learner@clf_lgb_tree_Id@18', 'Learner@clf_skl_rf_Id@8', 'Learner@clf_skl_lr_Id@7', 'Learner@clf_skl_lr_Id@6', 'Learner@clf_skl_lr_Id@4', 'Learner@clf_skl_lr_Id@5', 'Learner@clf_xgb_tree_Id@17']
